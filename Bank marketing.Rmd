---
title: "Term deposit subscription prediction using bank data"
author: "Hari Hara Priya Kannan"
output: html_notebook
---

#Introduction

The aim of this project is to build a model to predict whether an individual will subscribe to a term deposit or not. The data is sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing). 

Buisness Problem:
There has been a revenue decline for the Portuguese bank and they would like to know what actions to take. After investigation, we found out that the root cause is that their clients are not depositing as frequently as before. Knowing that term deposits allow banks to hold onto a deposit for a specific amount of time, so banks can invest in higher gain financial products to make a profit. In addition, banks also hold better chance to persuade term deposit clients into buying other products such as funds or insurance to further increase their revenues. As a result, the Portuguese bank would like to identify existing clients that have higher chance to subscribe for a term deposit and focus marketing effort on such clients.

#Methodology

We considered three classifiers - Naive Bayes (NB), Decision Tree , and Support Vector Machine (SVM). We split the full data set into 75% training set and 25% test set. Each set resembled the full data by having the same proportion of target classes i.e. approximately 90 % of individuals reponding 'no' and 10% reposponding 'yes' in the target variable. For fine-tuning process, we ran a ten-folded cross-validation stratified sampling on each classifier. We also study the effect of Principal Component Analysis on each of the classifiers.

#Classification Methods

##Load the data
All the necessary library packages are imported.

```{r message=FALSE, warning=FALSE}
library(readr)
library(ggplot2)
library(lattice)
library(plyr)
library(dplyr)
library(caret)
library(mlbench)
library(foreign)
library(ggplot2)
library(reshape)
library(scales)
library(e1071)
library(MASS)
library(klaR)
library(C50)
library(kernlab)
```

Read the data set on bank clients. Here, analysis is based on the smaller dataset that represents randomly selected 10% of the entire dataset, so that computationally demanding algorithms (eg: SVM) can be performed faster.

```{r message=FALSE, warning=FALSE}
bank <- read_delim("C:\\Sem2\\Machine Learning\\bank-additional\\bank-additional.csv",";", escape_double = FALSE, trim_ws = TRUE)
head(bank)
```

```{r}
bank <- na.omit(bank)
bank[, sapply( bank, is.character )] <- sapply( bank[, sapply( bank, is.character )], trimws)
```

To get an understanding of the data, lets visualize a few variables.

```{r}
table(bank$y)
```

The dataset contains 3668 ‘no’ responses and 451 ‘yes’ responses. Below is the distribution by occupation and age.

```{r}
barplot(table(bank$job),col="blue",ylab="No. of Clients",las=2,main="Job",cex.names = 0.8,cex.axis = 0.8)
```


```{r}
boxplot(bank$age~bank$y, main=" Age",ylab="Age of Clients",xlab="Deposit A/C Open or Not")
```


#Splitting the dataset for training and testing

Now the dataset of 4119 observations are splitted into training and test data. We use stratified sampling to split the data, so that distribution of the outcome within traning and testing datasets is preserved. We split the data with 75% (or 3090) of observations is used for training the model and 25% (or 1029) of observations is used to test the prediction outcome from the classifier model.

```{r}
set.seed(123456)
TrainingDataIndex <- createDataPartition(bank$y, p=0.75, list = FALSE)
train <- bank[TrainingDataIndex,]
test <-bank[-TrainingDataIndex,]
prop.table(table(train$y))
```

```{r}
nrow(train)
```

```{r}
prop.table(table(test$y))
```

```{r}
nrow(test)
```

Thus, stratified sampling has enabled to maintain the distribution with about 89% of clients have responded ‘no’ to opening a deposit in both testing and training data set.

#Classification Methods

###Decision Tree

##Training the model

After partitioning the data to train and test, use a 10 fold cross validation to evaluate the model

```{r message=FALSE, warning=FALSE}
TrainingParameters <- trainControl(method = "cv", number = 10, repeats = 5)
```

Then create the decision tree using the C5.0 algorithm.

```{r message=FALSE, warning=FALSE}
DecTreeModel <- train(y ~ ., data = train, 
                      method = "C5.0",
                      trControl= TrainingParameters,
                      na.action = na.omit)
```


Let us take a look at the model.

```{r}
DecTreeModel
```

```{r}
summary(DecTreeModel)
```

##Testing the Model

Based on confusion matrix for test data, using the decision tree model we have correctly classified 901 + 40 = 941 observations and misclassified 16 + 40 = 56 representing a 91% accuracy.

```{r}
DTPredictions <-predict(DecTreeModel, test, na.action = na.pass)
confusionMatrix(table(DTPredictions, test$y))
```



###Naive Bayes

##Training the Model

The next machine learning method used to predict if a customer opens a bank account is Naive Bayes method. The Naive Bayes method assumes independece among all the variables, i.e. the algorithm assumes that attributes such as job and education are independent from each other in predicting whether a customer will open a bank account or not.

```{r message=FALSE, warning=FALSE}
NBModel <- train(train[,-20], train$y, method = "nb",trControl= trainControl(method = "cv", number = 10, repeats = 5))
NBModel
```

After invoking the Naive Bayes method using training data set, lets feed test data to the model.

##Testing the model

Below confusion matrix by class y shows that there is 89% accuracy in classification per Naive Bayes method.

```{r message=FALSE, warning=FALSE}
NBPredictions <-predict(NBModel, test)
confusionMatrix(table(NBPredictions, test$y))
```


###Support Vector Machines

SVM is another classification method that can be used to predict if a client falls into either ‘yes’ or ‘no’ class.

##Training the model

As before, create a prediction model using svmPoly method.

```{r message=FALSE, warning=FALSE}
svm_model <- train(y~., data = train,
                   method = "svmPoly",
                   trControl= trainControl(method = "cv", number = 10, repeats = 5),
                   tuneGrid = data.frame(degree = 1,scale = 1,C = 1))
svm_model
```

After using polynomial kernal function to build a model, lets use test data to predict the accuracy of the model.

##Testing the model

```{r}
SVMPredictions <-predict(svm_model, test, na.action = na.pass)
confusionMatrix(table(SVMPredictions, test$y))
```

#Model Evaluation

We created three models above to classify whether a cutomer would open a bank account or not. Lets build some key performance indicators to understand which model is the most successful in predicting the customer’s decision.

The typically used performance metrics are:

precision: success rate in identifying whether a customer did not subscibe to the deposit account
recall: proportion of clients correctly or incorrectly predicted to unsubscribe to an account

The classification goal is to predict whether or not customers will subscribe to a term deposit. Here the positive class is ‘no’ or that a customer does not subscribe to a deposit. Thus, it is important to choose a model with a low recall, i.e. the model that should contain a lower proportion of true positives (customers that did not subscribe to the deposit) out of total actual positives. If the bank aggressively determines those customers that do not subscribe to the bank account, the bank will lose some customers.

In order to illustrate recall and precision for each model, lets compute the weighted F-measure. The R output of the Confusion Matrix of each model already calculates recall and precision indicated by sensitivity and Pos Pred Value respectively. Thus, we can compute weighted F-measure (giving equal weights to reall and precision) as below. We collect sensitivity and Pos Pred Value from confusion matrix to compute F-measure for each model.

```{r}
model = c("dec","nb","svm")
recall = c(0.9826, 0.9706, 0.9760)
precision = c(0.9260, 0.9242, 0.9284)
fmeasure <- 2 * precision * recall / (precision + recall)
eval_table = data.frame(model,recall,precision,fmeasure) 
eval_table
```

Based on the above table, Naive Bayes method is the recommended classification method as it contains lowest recall. We do not want a model that aggressively classifies a customer response as ‘no’, we want more customers to open a bank account.

#Tuning with Principal Component Analysis

Since the bank dataset on telephone calls contains multiple variables, we can perform a principal component analysis (PCA), a dimensionality reduction technique, to reduce some of the variables with less variance, such that we can improve the model performances by focusing only on those attributes with relatively high variance.

As before, we will partition the data to test and training and perform each classification method to predict whether or not a customer will open a bank account. The pca function in caret package in R is used to perform dimensionality reduction which will exclude all categorical variables in the bank dataset.

```{r}
TrainingDataIndex <- createDataPartition(bank$y, p=0.75, list = FALSE)
trainingData <- bank[TrainingDataIndex,]
testData <- bank[-TrainingDataIndex,]
```

##Decision Tree

The decision tree model uses PCA to predict the class variable with an accuracy of 89.3%. This is slightly lower than the accuracy produced without performing dimensionalty reduction (89.9%). However, this model DecTreeModel2 contains a higher precision, 91.3% compared to 90.4% of DTPredictions.

```{r message=FALSE, warning=FALSE}
set.seed(30)
DecTreeModel2 <- train(trainingData[,-20], trainingData$y, 
                       method = "C5.0",
                       trControl= trainControl(method = "cv", number = 10),
                       preProcess = c("pca"),
                       na.action = na.omit)
DTPredictions2 <-predict(DecTreeModel, testData, na.action = na.pass)
confusionMatrix(table(DTPredictions2, testData$y))
```

##Naive Bayes

With PCA, naive bayes method produces a higher accuracy of 88.6% compared to the accuracy produced with PCA, 87.7%, thus this model predict a higher true negative rate (customers identified as opening a bank account) compared to the model without PCA. This model produces the same recall in comparison to the naive bayes model without PCA. The specificity is significantly higher than that from without PCA (39% versus 30%). Specificity is instances of true negative (44) as a proportion of true negative and false positive (44 + 68). In the banking campaigns, we want to minimize false positives, i.e. identifying class variable as ‘no’ when a customer actually wants to a bank account.

```{r message=FALSE, warning=FALSE}
NBModel2 <- train(trainingData[,-20], trainingData$y, method = "nb",trControl= trainControl(method = "cv", number = 10, repeats = 5))
NBPredictions2 <-predict(NBModel2, testData, na.action = na.pass)
confusionMatrix(table(NBPredictions2, testData$y))
```

##Support Vector Machine

When using PCA with SVM polynomial model, the accuracy improved from 89.6% to 90.3%. However, the model using PCA produced higher false positives (the model predicted a ‘no’ when a customer subscibed to an account) and thus SVM using PCA produced a higher precision, 91.1% versus 90.7%

```{r message=FALSE, warning=FALSE}
set.seed(40)
TrainingDataIndex <- createDataPartition(bank$y, p=0.75, list = FALSE)
trainingData <- bank[TrainingDataIndex,]
testData <- bank[-TrainingDataIndex,]
SVModel2 <- train(y ~ ., data = trainingData,
                 method = "svmPoly",
                 preProcess = c("pca"),
                 trControl= trainControl(method = "cv", number = 10),
                 tuneGrid = data.frame(degree = 1,
                                       scale = 1,
                                       C = 1))
SVpredictions2 <-predict(SVModel2, testData, na.action = na.pass)
confusionMatrix(table(SVpredictions2, testData$y))
```

# Discussion

The previous section showed that all classifiers did not perform accurately in predicting the term deposit subcribers despite the stratified sampling. This implies the imbalance class problem was prevalent.The NB model assumes the descriptive features to follow normality that are not necessarily true. The solution would be a transformation on numeric features. 

# Conclusion

Among three classifiers, the Naive Bayes produces the best performance in predicting if an individual will subscribe to a term deposit or not. We split the data into training and test sets. After using the PCA, we observed that even though there is no improvement in the recall value, the method produces an higher accuracy. Also, the accuracy of all the models are almost close to each other. We can try to create an ensemble model to see if there is a significant improvement in the performance of the model.


